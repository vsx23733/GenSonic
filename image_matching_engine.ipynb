{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_ascii_spaces(input_file: str, output_file: str, max_empty_lines=0):\n",
    "    \"\"\"\n",
    "    Cleans excessive blank lines from an ASCII file.\n",
    "\n",
    "    Parameters:\n",
    "        input_file (str): Path to the original ASCII file.\n",
    "        output_file (str): Path to save the cleaned ASCII file.\n",
    "        max_empty_lines (int): Maximum consecutive empty lines allowed.\n",
    "    \"\"\"\n",
    "    with open(input_file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    cleaned_lines = []\n",
    "    empty_count = 0\n",
    "\n",
    "    for line in lines:\n",
    "        if line.strip() == \"\":\n",
    "            empty_count += 1\n",
    "        else:\n",
    "            empty_count = 0  # Reset if a non-empty line appears\n",
    "        \n",
    "        if empty_count <= max_empty_lines:\n",
    "            cleaned_lines.append(line)\n",
    "\n",
    "    with open(output_file, \"w\") as f:\n",
    "        f.writelines(cleaned_lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding the level...\n",
      "Number of sub-images: 200\n",
      "Original Image Size: 10240x1280\n",
      "Expected Grid: 40 rows × 5 cols = 200 sub-images\n",
      "Actual Number of Sub-images: 200\n",
      "Commercial level reassembled saved\n",
      "Constructing the ascii representation of the commercial level...\n",
      "Encoded commercial level saved as ascii_commercial_level.txt\n",
      "Encoding finished !!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical, Sequence\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "# Slice input level to 256x256 block\n",
    "def level_image_slicer(level_image_path, patch_size=256) -> list[Image.Image]:\n",
    "    \"\"\"\n",
    "    This function takes as input the image of a commercial level  and will return sliced images of 256x256 pixels\n",
    "    \"\"\"\n",
    "    level_image = Image.open(level_image_path).convert('RGB')\n",
    "    level_image_array = np.array(level_image)\n",
    "\n",
    "    h, w, _ = level_image_array.shape\n",
    "\n",
    "    patches = []\n",
    "    for i in range(0, h, patch_size):\n",
    "        for j in range(0, w, patch_size):\n",
    "            patch = level_image_array[i:i+patch_size, j:j+patch_size, :]\n",
    "            patch_image = Image.fromarray(patch)\n",
    "            patches.append(patch_image)\n",
    "\n",
    "    return patches\n",
    "\n",
    "\n",
    "# Slice 256x256 into slice 64x64\n",
    "def mid_block_slicer(mid_block_image, patch_size=64) -> list[Image.Image]:\n",
    "    \"\"\"\n",
    "    This function takes as input an image of 256x256 and will return sliced images of 16x16 pixels\n",
    "    \"\"\"\n",
    "    # mid_block_image = Image.open(mid_block_image_path).convert('RGB')\n",
    "    mid_block_image_array = np.array(mid_block_image, dtype=np.uint8)\n",
    "\n",
    "    h, w, _ = mid_block_image_array.shape\n",
    "\n",
    "    patches = []\n",
    "    for i in range(0, h, patch_size):\n",
    "        for j in range(0, w, patch_size):\n",
    "            patch = mid_block_image_array[i:i+patch_size, j:j+patch_size, :]\n",
    "            patch_image = Image.fromarray(patch)\n",
    "            patches.append(patch_image)\n",
    "\n",
    "    return patches\n",
    "\n",
    "\n",
    "# Assemble image using slices\n",
    "def assemble_image(sub_images, image_size, sub_image_size):\n",
    "    \"\"\"Assembles a list of image slices into a full image\"\"\"\n",
    "\n",
    "    grid_size = image_size // sub_image_size  # Number of slices per row/column\n",
    "\n",
    "    sub_images = [np.array(img) for img in sub_images]\n",
    "\n",
    "    rows = [np.hstack(sub_images[i * grid_size: (i + 1) * grid_size]) for i in range(grid_size)]\n",
    "    assembled_image = np.vstack(rows)\n",
    "\n",
    "    assembled_image = Image.fromarray(assembled_image.astype(np.uint8))\n",
    "\n",
    "    return assembled_image\n",
    "\n",
    "def assemble_image_updated(sub_images, image_size, sub_image_size):\n",
    "    \"\"\"Assembles a list of sub-images into a full rectangular image.\"\"\"\n",
    "    h, w = image_size\n",
    "    sub_h, sub_w = sub_image_size\n",
    "\n",
    "    grid_rows = w // sub_w  # Number of rows\n",
    "    grid_cols = h // sub_h  # Number of columns\n",
    "\n",
    "    if len(sub_images) != grid_rows * grid_cols:\n",
    "        raise ValueError(f\"Expected {grid_rows * grid_cols} sub-images, but got {len(sub_images)}.\")\n",
    "\n",
    "    sub_images = [np.array(img) for img in sub_images]\n",
    "    \n",
    "    # Reshape sub-images into rows\n",
    "    rows = [np.hstack(sub_images[i * grid_cols: (i + 1) * grid_cols]) for i in range(grid_rows)]\n",
    "    assembled_image = np.vstack(rows)\n",
    "\n",
    "    return Image.fromarray(assembled_image.astype(np.uint8))\n",
    "\n",
    "\n",
    "# Model for features extraction\n",
    "def create_model():\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    model = torch.nn.Sequential(*list(model.children())[:-1])\n",
    "    model = model.eval()\n",
    "\n",
    "    return model \n",
    "\n",
    "# Function to process the images before the extractor\n",
    "def transform_image(input_image: Image.Image) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda img: img.convert(\"RGB\")),\n",
    "    transforms.Resize((224, 224)), \n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    return transform(input_image).unsqueeze(0)\n",
    "\n",
    "# Function for features extraction\n",
    "def extract_features(image):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    image = transform_image(image)  \n",
    "\n",
    "    model = create_model()\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        features = model(image)\n",
    "\n",
    "    return features.view(2048)\n",
    "\n",
    "\n",
    "# Function to build the sprite pool\n",
    "def build_sprite_pool(sprite_pool_path: str) -> list:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    sprite_pool = []\n",
    "\n",
    "    for sprite_path in os.listdir(sprite_pool_path):\n",
    "        sprite_pool.append(Image.open(os.path.join(sprite_pool_path, sprite_path)))\n",
    "\n",
    "    return sprite_pool\n",
    "\n",
    "\n",
    "# Building database of emebdding (embedding  pool)\n",
    "def build_embedding_database(sprite_pool : list):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    sprite_embeddings_dict = {}\n",
    "    sprite_image_dict = {}\n",
    "\n",
    "    for i, sprite_image in enumerate(sprite_pool): # mapper_image_to_name.values()\n",
    "        sprite_embeddings_dict[i] = extract_features(sprite_image)\n",
    "        sprite_image_dict[i] = sprite_image\n",
    "\n",
    "    return sprite_image_dict, sprite_embeddings_dict\n",
    "\n",
    "\n",
    "\n",
    "# Function to find the closest match of a slice in the sprite pool\n",
    "def find_closest_match(input_image : Image.Image, embeddings_pool : dict, feature_extractor) -> tuple:\n",
    "    \"\"\"\n",
    "    Takes as input an image and find the closest image in the provided image pool embedding\n",
    "    The similarity function used here is the cosine similarity\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(input_image, Image.Image):\n",
    "        input_features = extract_features(input_image)  \n",
    "    elif not isinstance(input_image, torch.Tensor):\n",
    "        raise TypeError(f\"Unexpected input type {type(input_image)}\")\n",
    "\n",
    "    similarity_scores = []\n",
    "    #input_features = feature_extractor(input_image)\n",
    "    #input_features = input_features.view(-1)\n",
    "        \n",
    "    for sprite_feature in embeddings_pool.values():\n",
    "\n",
    "        sprite_feature = sprite_feature.view(-1) \n",
    "\n",
    "        similarity_score = F.cosine_similarity(\n",
    "                    sprite_feature.unsqueeze(0),  \n",
    "                    input_features.unsqueeze(0)\n",
    "            ).item()\n",
    "        similarity_scores.append(similarity_score)\n",
    "    \n",
    "\n",
    "    best_score = max(similarity_scores)\n",
    "    best_idx = similarity_scores.index(best_score)\n",
    "    best_match = embeddings_pool[best_idx]\n",
    "    return best_match, best_idx\n",
    "\n",
    "# Load ascii representation of a file\n",
    "def load_ascii_from_file(file_path: str) -> list:\n",
    "    \"\"\"Load ASCII art from a text file and return it as a list of strings (rows).\"\"\"\n",
    "    with open(file_path, \"r\") as f:\n",
    "        return f.read().splitlines()\n",
    "    \n",
    "\n",
    "# Get the file name based on array of input image (value)\n",
    "def get_key_by_value(d: dict, value) -> str:\n",
    "    for key, val in d.items():\n",
    "        val = np.array(val)\n",
    "        if np.allclose(val, value, rtol=1e-5, atol=1):\n",
    "            return key\n",
    "    print(\"⚠️ Warning: No exact match found, returning default block\")\n",
    "    return \"default_block\"  # Ensure \"default_block.txt\" exists\n",
    "\n",
    "def load_mappers(mapper_image_to_name_path: str,\n",
    "                 mapper_name_to_ascii_path: str\n",
    "                 ) -> tuple[dict, dict]:\n",
    "    \n",
    "    with open(mapper_image_to_name_path, \"r\") as f:\n",
    "        mapper_image_to_name = json.load(f)\n",
    "        \n",
    "    with open(mapper_name_to_ascii_path, \"r\") as f:\n",
    "        mapper_name_to_ascii = json.load(f)\n",
    "    \n",
    "    return mapper_image_to_name, mapper_name_to_ascii\n",
    "\n",
    "\n",
    "\n",
    "# Construct the ascii representation of a block 256x256\n",
    "def image_to_ascii(input_block_image: Image.Image, sub_image_size: int, mapper_image_to_name: dict, mapper_name_to_ascii: dict, file_name: str, output_path: str):\n",
    "    \"\"\"\n",
    "    Build the ascii equivalent of an image.\n",
    "\n",
    "    Parameters:\n",
    "        input_block_image : Input image block which will be encoded in ascii. Expecting 256x256 blocks or the image level or the commercial level.\n",
    "        sub_image_size : The dimension by which the size of the input image block will be divided\n",
    "        mapper_image_to_name : The dictionary mapping the slice (sub_image_size x sub_image_size) to their ID (name).\n",
    "        mapper_name_to_ascii : The dictionary mapping the ID of the slice (name) to the corresponding ASCII character.\n",
    "        file_name: The name of the output file.\n",
    "    \"\"\"\n",
    "\n",
    "    input_block_image_array = np.array(input_block_image)\n",
    "    # Resize the grayscale image\n",
    "    input_block_image_array = cv2.resize(input_block_image_array, (128, 128), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    # Now unpack the shape correctly\n",
    "    h, w = input_block_image_array.shape\n",
    "\n",
    "    file_height = int(h / sub_image_size)\n",
    "    file_width = int(w / sub_image_size)\n",
    "\n",
    "    ascii_image = []\n",
    "\n",
    "    for i in range(file_height):\n",
    "        row = []\n",
    "        for j in range(file_width):\n",
    "            sub_block_array = input_block_image_array[(i*sub_image_size):(i*sub_image_size)+sub_image_size, \n",
    "                                                      (j*sub_image_size):(j*sub_image_size)+sub_image_size]\n",
    "            sub_block_name = \"\"\n",
    "\n",
    "            # Compare sub-block to find the matching sprite in the dictionary\n",
    "            for sprite_name, sprite in mapper_image_to_name.items():\n",
    "                sprite = np.array(sprite, dtype=np.uint8)\n",
    "                # Convert sprite to grayscale\n",
    "                if len(sprite.shape) == 3:  \n",
    "                    sprite = cv2.cvtColor(sprite, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "                if len(sub_block_array.shape) == 3:\n",
    "                    sub_block_array = cv2.cvtColor(sub_block_array, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "                if np.allclose(sprite, sub_block_array, rtol=1e-5, atol=1):\n",
    "                    #print(sprite_name)\n",
    "                    sub_block_name = sprite_name\n",
    "                    break\n",
    "\n",
    "            #if sub_block_name == \"\":\n",
    "            #    print(\"No block found !!\")\n",
    "\n",
    "            sub_block_ascii = mapper_name_to_ascii.get(sub_block_name, \" \")  # Default to space if no match found\n",
    "            row.append(sub_block_ascii)\n",
    "        \n",
    "        ascii_image.append(''.join(row))\n",
    "\n",
    "    with open(os.path.join(output_path, file_name), \"w\") as f:\n",
    "        for row in ascii_image:\n",
    "            f.write(row + \"\\n\")\n",
    "\n",
    "    return ascii_image\n",
    "\n",
    "\n",
    "# Create the ascii representation of the commercial level\n",
    "def compose_ascii(large_image: Image.Image, block_size: int, slice_size: int,\n",
    "                              ascii_folder: str, output_file: str, block_to_ascii: dict):\n",
    "    \"\"\"\n",
    "    Create the ASCII equivalent of a large image using precomputed ASCII blocks.\n",
    "    \n",
    "    Parameters:\n",
    "        large_image : PIL Image of the large image to be converted.\n",
    "        block_size : The size of each block (assumes square blocks, e.g., 256x256).\n",
    "        slice_size : The size of each slice of the block (32x32 or 64x64)\n",
    "        ascii_folder : Folder containing the ASCII block text files.\n",
    "        output_file : The file name to save the ASCII output.\n",
    "        block_to_ascii : Maps each block to its ASCII representation. Key is file name and value the array of the block. \n",
    "        \n",
    "    \"\"\"\n",
    "    # Convert the large image to a numpy array\n",
    "    # gray_large_image = large_image.convert(\"L\")\n",
    "    large_image_array = np.array(large_image)\n",
    "    h, w = large_image_array.shape\n",
    "    assert h % block_size == 0 and w % block_size == 0, \"Image dimensions must be multiples of block_size\"\n",
    "    \n",
    "    ascii_blocks = {} # key: file_name, value: ascii\n",
    "    for filename in os.listdir(ascii_folder):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            block_name = filename.split(\".\")[0]  # Use filename as a key\n",
    "            file_path = os.path.join(ascii_folder, filename)\n",
    "            ascii_blocks[block_name] = load_ascii_from_file(file_path)\n",
    "    \n",
    "    ascii_representation = []\n",
    "    \n",
    "    # Process the large image in blocks\n",
    "    for i in range(0, h, block_size):\n",
    "        ascii_rows = [\"\" for _ in range(block_size)]  # Prepare rows to append ASCII text\n",
    "        for j in range(0, w, block_size):\n",
    "            block = large_image_array[i:i+block_size, j:j+block_size]\n",
    "            block_name = get_key_by_value(\n",
    "                d=block_to_ascii,\n",
    "                value=block\n",
    "            ) # Retrieve the filename based on the image block\n",
    "            block_name = block_name.split(\".\")[0] # Retrieve the file name of the ascii based on array block\n",
    "            \n",
    "            matched_ascii = ascii_blocks.get(block_name, [\" \" * block_size] * block_size) # Retrieve the ascii corresponding\n",
    "            \n",
    "            for k in range(len(matched_ascii)):  # Use actual ASCII block length\n",
    "                ascii_rows[k] += matched_ascii[k]\n",
    "        \n",
    "        # Append full ASCII block rows to final representation\n",
    "        ascii_representation.extend(ascii_rows)\n",
    "    \n",
    "    # Save to file\n",
    "    with open(output_file, \"w\") as f:\n",
    "        for row in ascii_representation:\n",
    "            f.write(row + \"\\n\")\n",
    "    \n",
    "    return ascii_representation\n",
    "\n",
    "\n",
    "# Clean the ascii file from empty lines\n",
    "def clean_ascii_spaces(input_file: str, output_file: str, max_empty_lines=0):\n",
    "    \"\"\"\n",
    "    Cleans excessive blank lines from an ASCII file.\n",
    "\n",
    "    Parameters:\n",
    "        input_file (str): Path to the original ASCII file.\n",
    "        output_file (str): Path to save the cleaned ASCII file.\n",
    "        max_empty_lines (int): Maximum consecutive empty lines allowed.\n",
    "    \"\"\"\n",
    "    with open(input_file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    cleaned_lines = []\n",
    "    empty_count = 0\n",
    "\n",
    "    for line in lines:\n",
    "        if line.strip() == \"\":\n",
    "            empty_count += 1\n",
    "        else:\n",
    "            empty_count = 0  # Reset if a non-empty line appears\n",
    "        \n",
    "        if empty_count <= max_empty_lines:\n",
    "            cleaned_lines.append(line)\n",
    "\n",
    "    with open(output_file, \"w\") as f:\n",
    "        f.writelines(cleaned_lines)\n",
    "\n",
    "\n",
    "# The auto-encoder function\n",
    "def auto_encoder(commercial_level_path: str,\n",
    "                 sprite_pool_path: str, \n",
    "                 mapper_image_to_name_path: str,\n",
    "                 mapper_name_to_ascii_path: str,\n",
    "                 model):\n",
    "    \n",
    "    mapper_image_to_name, mapper_name_to_ascii = load_mappers(mapper_image_to_name_path, mapper_name_to_ascii_path)\n",
    "    \n",
    "    if not os.path.exists(sprite_pool_path) or not os.listdir(sprite_pool_path):\n",
    "        raise ValueError(f\"Sprite pool path {sprite_pool_path} is invalid or empty.\")\n",
    "    \n",
    "\n",
    "    # Defining path of images and txt file \n",
    "    block_output_path = \"commercial_block_folder\" # To save the blocks 256x256\n",
    "    block_slices_path = \"block_slices_folder\" # To save the slices 64x64\n",
    "    reassembled_block_output_path = \"reassembled_commercial_block_folder\" # To save the reasselbled 256x256\n",
    "    ascii_output_path = \"ascii_block_folder\" # To save the ascii of the 256x256 block \n",
    "    os.makedirs(block_output_path, exist_ok=True)\n",
    "    os.makedirs(block_slices_path, exist_ok=True)\n",
    "    os.makedirs(reassembled_block_output_path, exist_ok=True)\n",
    "    os.makedirs(ascii_output_path, exist_ok=True)\n",
    "\n",
    "\n",
    "    \n",
    "    first_level_sprite_pool_path = sprite_pool_path  \n",
    "    sprite_pool = [Image.open(os.path.join(first_level_sprite_pool_path, sprite_path)) \n",
    "                   for sprite_path in os.listdir(first_level_sprite_pool_path)]\n",
    "\n",
    "    if len(sprite_pool) < 35:\n",
    "        print(f\"Warning: Sprite pool contains only {len(sprite_pool)} images.\")\n",
    "\n",
    "    sprite_pool = build_sprite_pool(sprite_pool_path)  # Limit to first 35 images\n",
    "    # sprite_pool = sprite_pool[:35]\n",
    "    \n",
    "    # Create sprite embeddings pool\n",
    "    sprite_image_dict, sprite_embeddings_dict = build_embedding_database(sprite_pool=sprite_pool)\n",
    "\n",
    "    \n",
    "    # Slice the commercial level image\n",
    "    commercial_lvl_img_patch = level_image_slicer(\n",
    "        level_image_path=commercial_level_path, \n",
    "        patch_size=256\n",
    "    )\n",
    "\n",
    "    # data\n",
    "    \n",
    "    block_to_ascii = {}  \n",
    "    commercial_lvl_reassambled_block_L = []\n",
    "    commercial_lvl_reassambled_block = []\n",
    "\n",
    "    # Saving each sliced block\n",
    "    for k, block in enumerate(commercial_lvl_img_patch):\n",
    "        block_path = os.path.join(block_output_path, f\"initial_block_{k+1}.png\")\n",
    "        block.save(block_path)\n",
    "        #print(f\"initial_block_{k+1}.png saved\")\n",
    "\n",
    "    for i, img_block in enumerate(commercial_lvl_img_patch):\n",
    "        block_folder = os.path.join(block_slices_path, f\"block_{i+1}\")\n",
    "        match_folder = os.path.join(block_folder, f\"block_match_{i+1}\")\n",
    "        os.makedirs(block_folder, exist_ok=True)\n",
    "        os.makedirs(match_folder, exist_ok=True) \n",
    "        \n",
    "        # Slice each block of 256x256\n",
    "\n",
    "        img_block_slices = mid_block_slicer(img_block, patch_size=64)\n",
    "        img_block_slices_matches_L = []\n",
    "        img_block_slices_matches = []\n",
    "        \n",
    "        # Find closest match of the slice and saving it\n",
    "\n",
    "        for j, slice in enumerate(img_block_slices): \n",
    "            match_idx = find_closest_match(slice, sprite_embeddings_dict, model)[1]\n",
    "            matched_sprite = sprite_image_dict[match_idx]\n",
    "            # img_block_slices_matches.append(matched_sprite)\n",
    "            img_block_slices_matches.append(matched_sprite)\n",
    "            slice_path = os.path.join(block_folder, f\"slice_{j+1}.png\")\n",
    "            slice_match_path = os.path.join(match_folder, f\"slice_match_{j+1}.png\")\n",
    "            slice.save(slice_path)\n",
    "            matched_sprite.save(slice_match_path)\n",
    "\n",
    "        # Using saved matched to reassemble the 256x256 block and save reassembled block\n",
    "\n",
    "        for slice_path in os.listdir(match_folder):\n",
    "            slice_path = os.path.join(match_folder, slice_path)\n",
    "            slice = Image.open(slice_path).convert(\"L\")\n",
    "            img_block_slices_matches_L.append(slice)\n",
    "        \n",
    "        img_block_reassembled = assemble_image_updated(\n",
    "            sub_images=img_block_slices_matches,\n",
    "            image_size=(128, 128),\n",
    "            sub_image_size=(32, 32)\n",
    "        ) # For ascii recontruction\n",
    "        img_block_reassembled_L = assemble_image_updated(\n",
    "            sub_images=img_block_slices_matches_L,\n",
    "            image_size=(128, 128),\n",
    "            sub_image_size=(32, 32)\n",
    "        ) # To save the image\n",
    "\n",
    "        img_block_reassembled_path = os.path.join(reassembled_block_output_path, f\"reassembled_block_{i+1}.png\")\n",
    "        img_block_reassembled_L.save(img_block_reassembled_path)\n",
    "        #print(f\"Block reassembled {i+1} saved\")\n",
    "\n",
    "        \n",
    "        reassembled_block = Image.open(img_block_reassembled_path) # L mode Image\n",
    "        commercial_lvl_reassambled_block_L.append(reassembled_block) # L commercial image block\n",
    "        commercial_lvl_reassambled_block.append(img_block_reassembled) # Normal commercial image block\n",
    "\n",
    "        file_name = f\"img_block_{i+1}.txt\"\n",
    "        image_to_ascii(\n",
    "            input_block_image=img_block_reassembled,  \n",
    "            sub_image_size=32,\n",
    "            mapper_image_to_name=mapper_image_to_name,\n",
    "            mapper_name_to_ascii=mapper_name_to_ascii,\n",
    "            file_name=file_name,\n",
    "            output_path=ascii_output_path\n",
    "        )\n",
    "        img_block_reassembled = img_block_reassembled.resize((256, 256))\n",
    "        block_to_ascii[file_name] = np.array(img_block_reassembled).tolist()\n",
    "\n",
    "    commercial_lvl_image = Image.open(commercial_level_path)\n",
    "    h, w = commercial_lvl_image.size\n",
    "\n",
    "    print(f\"Number of sub-images: {len(commercial_lvl_reassambled_block_L)}\")\n",
    "\n",
    "    print(f\"Original Image Size: {h}x{w}\")\n",
    "    print(f\"Expected Grid: {h // 256} rows × {w // 256} cols = {(h // 256) * (w // 256)} sub-images\")\n",
    "    print(f\"Actual Number of Sub-images: {len(commercial_lvl_reassambled_block_L)}\")\n",
    "\n",
    "\n",
    "    resized_commercial_lvl_reassambled_block_L = [img.resize((256, 256)) for img in commercial_lvl_reassambled_block_L]\n",
    "    resized_commercial_lvl_reassambled_block = [img.resize((256, 256)) for img in commercial_lvl_reassambled_block]\n",
    "\n",
    "    # Final reconstruction\n",
    "    commercial_lvl_reassambled_L = assemble_image_updated(\n",
    "        sub_images=resized_commercial_lvl_reassambled_block_L,\n",
    "        image_size=(h, w),\n",
    "        sub_image_size=(256, 256) \n",
    "    ) # For image saving\n",
    "    \n",
    "    \n",
    "    commercial_lvl_reassambled = assemble_image_updated(\n",
    "        sub_images=resized_commercial_lvl_reassambled_block,\n",
    "        image_size=(h, w),\n",
    "        sub_image_size=(256, 256)  \n",
    "    ) # For image reconstruction\n",
    "\n",
    "    print(\"Commercial level reassembled saved\")\n",
    "    commercial_lvl_reassambled_L.convert(\"L\").save(\"reassembled_commercial_level.png\")\n",
    "\n",
    "    # Final ascii encoding\n",
    "    ascii_folder = r\"C:\\Users\\axelo\\Documents\\Projects\\level-auto-encoder\\ascii_block_folder\"\n",
    "    os.makedirs(ascii_folder, exist_ok=True)\n",
    "\n",
    "\n",
    "    print(\"Constructing the ascii representation of the commercial level...\")\n",
    "    encoded_commercial_level = \"ascii_commercial_level.txt\"\n",
    "    ascii_representation_lvl = compose_ascii(\n",
    "        large_image=commercial_lvl_reassambled,\n",
    "        block_size=256,\n",
    "        slice_size=64,\n",
    "        ascii_folder=ascii_folder,\n",
    "        output_file=encoded_commercial_level,\n",
    "        block_to_ascii=block_to_ascii\n",
    "    )\n",
    "    if ascii_representation_lvl:\n",
    "        print(f\"Encoded commercial level saved as {encoded_commercial_level}\")\n",
    "    else:\n",
    "        print(\"Failed to encode commercial level\")\n",
    "\n",
    "model = create_model()\n",
    "print(\"Encoding the level...\")\n",
    "auto_encoder(\n",
    "        commercial_level_path=r\"C:\\Users\\axelo\\Documents\\COURS PGE 3\\AI CLINIC\\S1\\level-auto-encoder\\Sonic1_MD_Map_Ghz1.png\",\n",
    "        sprite_pool_path=r\"C:\\Users\\axelo\\Documents\\COURS PGE 3\\AI CLINIC\\S1\\level-auto-encoder\\sprite_pool_level_1\",\n",
    "        mapper_image_to_name_path=r\"C:\\Users\\axelo\\Documents\\COURS PGE 3\\AI CLINIC\\S1\\level-auto-encoder\\sprites_data\\level_1.json\",\n",
    "        mapper_name_to_ascii_path=r\"C:\\Users\\axelo\\Documents\\COURS PGE 3\\AI CLINIC\\S1\\level-auto-encoder\\sprites_token\\lvl_1_token_mapping.json\",\n",
    "        model=model\n",
    "    )\n",
    "print(\"Encoding finished !!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image comparison script\n",
    "\n",
    "###########################\n",
    "### Comparison pipeline ###\n",
    "###########################\n",
    "\n",
    "# Extract features --> Cosine similarity \n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def extract_features(input_image):\n",
    "    \"\"\"\n",
    "    Use a pretrained model to extract feature of the input image\n",
    "    \"\"\"\n",
    "    transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda img: img.convert(\"RGB\")),\n",
    "    transforms.Resize((224, 224)), \n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    processed_input_image = transform(input_image).unsqueeze(0)\n",
    "\n",
    "    feature_extractor = models.resnet50(pretrained=True)\n",
    "    feature_extractor = torch.nn.Sequential(*list(feature_extractor.children())[:-1])\n",
    "    feature_extractor = feature_extractor.eval()\n",
    "\n",
    "    features = feature_extractor(processed_input_image)\n",
    "    return features\n",
    "\n",
    "def compute_similarity_score(img1_path, img2_path):\n",
    "    \"\"\"\n",
    "    Compute the similarity score of the input images\n",
    "    \"\"\"\n",
    "    img1 = Image.open(img1_path)\n",
    "    img2 = Image.open(img2_path)\n",
    "    \n",
    "    feature_img1 = extract_features(img1)\n",
    "    feature_img2 = extract_features(img2)\n",
    "\n",
    "    similarity_score = cosine_similarity(feature_img1, feature_img2)\n",
    "\n",
    "    return similarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_path = r\"C:\\Users\\axelo\\Documents\\COURS PGE 3\\AI CLINIC\\S1\\level-auto-encoder\\reassembled_commercial_level.png\"\n",
    "img2_path = r\"C:\\Users\\axelo\\Documents\\COURS PGE 3\\AI CLINIC\\S1\\level-auto-encoder\\Sonic1_MD_Map_Ghz1.png\"\n",
    "\n",
    "cosine_similarity(img1_path, img2_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping saved to ascii_mapping.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "lvl_1_json_path = r\"C:/Users/axelo/Documents/Projects/level-auto-encoder/sprites_token/full_token/level_1_full_token.json\"\n",
    "\n",
    "with open(lvl_1_json_path, \"r\") as f:\n",
    "    lvl_1_json = json.load(f)\n",
    "\n",
    "keys = list(lvl_1_json.keys())\n",
    "\n",
    "start_unicode = 0x0100  # 'Ā' (Latin Extended-A)\n",
    "\n",
    "# Create the mapping\n",
    "dictionary_mapping = {key: chr(start_unicode + i) for i, key in enumerate(keys)}\n",
    "\n",
    "with open(\"ascii_mapping.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(dictionary_mapping, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(\"Mapping saved to ascii_mapping.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_json(json_file: str):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    import json\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    reversed_data = {}\n",
    "    for key, value in data.items():\n",
    "        reversed_data[value] = key\n",
    "    \n",
    "    with open(\"reversed_data.json\", \"w\", encoding=\"windows-1252\") as f:\n",
    "        json.dump(reversed_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_json(json_file=r\"C:\\Users\\axelo\\Documents\\COURS PGE 3\\AI CLINIC\\S1\\level-auto-encoder\\lvl_1_token_mapping.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
